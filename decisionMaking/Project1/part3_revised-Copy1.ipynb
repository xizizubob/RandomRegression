{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import math\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn import linear_model\n",
    "import patsy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from __future__ import division\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Baseline Model \n",
    "## pt a Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"NRDF.xlsx\")\n",
    "SaleOver2k = (np.array([data['SalePrice']>200000])*1).reshape(len(data),1)\n",
    "data = data.assign(SaleOver2k = SaleOver2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "test.to_csv('test.csv')\n",
    "data = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataCVforLinearModels(data,target,log):\n",
    "    training, testing = train_test_split(data, test_size=0.2)\n",
    "    if log == 'log':\n",
    "        training = training.set_index([list(range(len(training)))])\n",
    "        for i in range(len(training[\"SalePrice\"])):\n",
    "            training.loc[i,('SalePrice')] = math.log(training.loc[i,('SalePrice')])\n",
    "        testing = testing.set_index([list(range(len(testing)))])\n",
    "        for i in range(len(testing[\"SalePrice\"])):\n",
    "            testing.loc[i,('SalePrice')] = math.log(testing.loc[i,('SalePrice')])\n",
    "        test_x=testing.drop(['SalePrice'],axis = 1)\n",
    "        test_y=testing['SalePrice']\n",
    "    X = training.drop([target], axis=1)\n",
    "    Y = training[target]\n",
    "    test_x=testing.drop([target], axis=1)\n",
    "    test_y=testing[target]\n",
    "    return training,testing,X,Y,test_x,test_y\n",
    "\n",
    "def linearRegression(data,target):\n",
    "    lm = smf.ols(target+' ~ '+' + '.join(list(data.drop([target], axis=1))), data=data).fit()\n",
    "    return lm\n",
    "\n",
    "def logisticRegression(data,target):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train.drop([target],axis=1),train[target])\n",
    "    return lr\n",
    "\n",
    "def CVforRegModels(data,target,lm,log):\n",
    "    insample_r2=[]\n",
    "    outsample_r2=[]\n",
    "    outsample_rsme=[]\n",
    "    for i in range (5):\n",
    "        training,testing,X,Y,test_x,test_y = dataCVforLinearModels(data,target,log)\n",
    "        if lm == \"linear\":\n",
    "            lm = linearRegression(training,target)\n",
    "        elif lm == \"logistic\": \n",
    "            lm = logisticRegression(training,target)\n",
    "        rsq = 1. - np.sum((lm.predict(X)-Y)**2)/np.sum((\n",
    "        Y.mean()-Y)**2)\n",
    "        insample_r2.append(rsq)\n",
    "        rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((\n",
    "        test_y.mean()-test_y)**2)\n",
    "        outsample_r2.append(rsq)\n",
    "        rsme = sqrt(mean_squared_error(test_y, lm.predict(test_x)))\n",
    "        outsample_rsme.append(rsme)\n",
    "    print \"Estimated out of sample Root mean squared error for this model is \", sum(outsample_rsme)/5\n",
    "    print 'Estimated out of sample R-square for this model is',sum(outsample_r2)/5\n",
    "    print 'Estimated in sample R-square for this model is',sum(insample_r2)/5\n",
    "    \n",
    "def CVforClassificationModels(data,target,lm,log):\n",
    "    insample_r2=[]\n",
    "    outsample_r2=[]\n",
    "    outsample_rsme=[]\n",
    "    for i in range (5):\n",
    "        training,testing,X,Y,test_x,test_y = dataCVforLinearModels(data,target,log)\n",
    "        if lm == \"linear\":\n",
    "            lm = linearRegression(training,target)\n",
    "        elif lm == \"logistic\": \n",
    "            lm = logisticRegression(training,target)\n",
    "        ab = sum((lm.predict(X)>0.5)*1*Y )/sum(Y)\n",
    "        insample_r2.append(ab)\n",
    "        ac = sum((lm.predict(test_x)>0.5)*1*test_y )/sum(test_y)\n",
    "        outsample_r2.append(ac)\n",
    "    print 'Estimated out of sample accuracy for this model is',sum(outsample_r2)/5\n",
    "    print 'Estimated in sample accuracy for this model is',sum(insample_r2)/5\n",
    "    \n",
    "def FinalClassificationTest(data,target,lm,log):\n",
    "    insample_r2=[]\n",
    "    outsample_r2=[]\n",
    "    outsample_rsme=[]\n",
    "    for i in range (5):\n",
    "        training,testing,X,Y,test_x,test_y = dataCVforLinearModels(data,target,log)\n",
    "        if lm == \"linear\":\n",
    "            lm = linearRegression(training,target)\n",
    "        elif lm == \"logistic\": \n",
    "            lm = logisticRegression(training,target)\n",
    "        ab = sum((lm.predict(X)>0.5)*1*Y )/sum(Y)\n",
    "        insample_r2.append(ab)\n",
    "        ac = sum((lm.predict(test_x)>0.5)*1*test_y )/sum(test_y)\n",
    "        outsample_r2.append(ac)\n",
    "    print 'Final Test Result for accurancy is ',sum(outsample_r2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-693-58f93ab5b6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCVforRegModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SaleOver2k'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'logistic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-692-ec6fad1e0f6c>\u001b[0m in \u001b[0;36mCVforRegModels\u001b[0;34m(data, target, lm, log)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"logistic\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         rsq = 1. - np.sum((lm.predict(X)-Y)**2)/np.sum((\n\u001b[1;32m     38\u001b[0m         Y.mean()-Y)**2)\n",
      "\u001b[0;32m<ipython-input-692-ec6fad1e0f6c>\u001b[0m in \u001b[0;36mlogisticRegression\u001b[0;34m(data, target)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xizizhu/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xizizhu/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CVforRegModels(train.drop(['SaleOver2k'], axis=1),'SalePrice','logistic','none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt a Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linearRegression(data.drop(['SalePrice'], axis=1),'SaleOver2k')\n",
    "CVforClassificationModels(data,'SaleOver2k',lm,'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-0 Loss function is not a useful point of reference in this case for example: it might not punish the price\n",
    "##### large enough and a sale price way below 200,000 and one that is close to 200,000 are totally different, but 1-0\n",
    "##### loss function rates them the same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt c Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_excel(\"NewData.xlsx\")\n",
    "singlefeatures = data2.columns[:-1]\n",
    "features = list(singlefeatures)\n",
    "for i in range(len(features)):\n",
    "    features[i] = \"\".join(features[i].split())\n",
    "    features[i] = features[i].replace('.','DOT')\n",
    "singlefeatures = features\n",
    "features.append('SalePrice')\n",
    "data2.columns = features\n",
    "train2, test2 = train_test_split(data2, test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results from the selected variable model\n",
    "insample_r2=[]\n",
    "outsample_r2=[]\n",
    "outsample_rsme=[]\n",
    "for i in range (5):\n",
    "    training, testing = train_test_split(train2, test_size=0.2)\n",
    "    X = training.drop(['SalePrice'],axis = 1)\n",
    "    Y = training['SalePrice']\n",
    "    test_x=testing.drop(['SalePrice'],axis = 1)\n",
    "    test_y=testing['SalePrice']\n",
    "    lm = smf.ols('SalePrice ~ '+' + '.join(list(X)), data=training).fit()\n",
    "    insample_r2.append(lm.rsquared)\n",
    "    rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((test_y.mean()-test_y)**2)\n",
    "    outsample_r2.append(rsq)\n",
    "    rsme = sqrt(mean_squared_error(test_y, lm.predict(test_x)))\n",
    "    outsample_rsme.append(rsme)\n",
    "print \"Estimated out of sample Root mean squared error for this model is \", sum(outsample_rsme)/5\n",
    "print 'Estimated out of sample R-square for this model is',sum(outsample_r2)/5\n",
    "print 'Estimated in sample R-square for this model is',sum(insample_r2)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model performs slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt c classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['SalePrice','SaleOver2k'], axis=1)\n",
    "Y = data['SaleOver2k']\n",
    "alpha=np.arange(20,40,1)\n",
    "singlefeatures = list(X)\n",
    "lasso = linear_model.LassoCV(alphas=alpha,cv =5).fit(X,Y)\n",
    "Importantfeatures = np.array(singlefeatures)[np.abs(lasso.coef_)>1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(data[Importantfeatures],data['SaleOver2k'])\n",
    "Importantfeatures = list(set(Importantfeatures))\n",
    "Importantfeatures.append('SaleOver2k')\n",
    "CVforClassificationModels(data[Importantfeatures],'SaleOver2k',lr,\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### they do not having a great in-sample score and \n",
    "#### out-sample is almost random. It does not perform as\n",
    "#### good as baseline model (almost random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 Baseline Model \n",
    "## pt a Best Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression with Lasso\n",
    "insample_r2=[]\n",
    "outsample_r2=[]\n",
    "outsample_rsme=[]\n",
    "for i in range (5):\n",
    "    training, testing = train_test_split(train, test_size=0.2)\n",
    "    X = training.drop(['SalePrice','SaleOver2k'], axis=1)\n",
    "    Y = training['SalePrice']\n",
    "    test_x=testing.drop(['SalePrice','SaleOver2k'], axis=1)\n",
    "    test_y=testing['SalePrice']\n",
    "    alpha=np.arange(0,30,0.1)\n",
    "    singlefeatures = list(X)\n",
    "    lasso = linear_model.LassoCV(alphas=alpha,cv =5).fit(X,Y)\n",
    "    lassofeatures = np.array(singlefeatures)[np.abs(lasso.coef_)>1e-10]\n",
    "    lm = smf.ols('SalePrice ~ '+' + '.join(lassofeatures), data=training).fit()\n",
    "    insample_r2.append(lm.rsquared)\n",
    "    rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((\n",
    "    test_y.mean()-test_y)**2)\n",
    "    outsample_r2.append(rsq)\n",
    "    rsme = sqrt(mean_squared_error(test_y, lm.predict(test_x)))\n",
    "    outsample_rsme.append(rsme)\n",
    "print \"Estimated out of sample Root mean squared error for this model is \", sum(outsample_rsme)/5\n",
    "print 'Estimated out of sample R-square for this model is',sum(outsample_r2)/5\n",
    "print 'Estimated in sample R-square for this model is',sum(insample_r2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression with Ridge\n",
    "insample_r2=[]\n",
    "outsample_r2=[]\n",
    "outsample_rsme=[]\n",
    "for i in range (5):\n",
    "    training, testing = train_test_split(train, test_size=0.2)\n",
    "    X = training.drop(['SalePrice','SaleOver2k'], axis=1)\n",
    "    Y = training['SalePrice']\n",
    "    test_x=testing.drop(['SalePrice','SaleOver2k'], axis=1)\n",
    "    test_y=testing['SalePrice']\n",
    "    alpha=np.arange(0,30,0.1)\n",
    "    ridge = linear_model.RidgeCV(alphas=alpha,cv =5).fit(X,Y)\n",
    "    R2=ridge.score(X,Y)\n",
    "    insample_r2.append(R2)\n",
    "    Prediction = ridge.predict(test_x)\n",
    "    R2_out = 1. - np.sum((Prediction-test_y)**2)/np.sum((\n",
    "    test_y.mean()-test_y)**2)\n",
    "    outsample_r2.append(R2_out)\n",
    "    rsme = sqrt(mean_squared_error(test_y, Prediction))\n",
    "    outsample_rsme.append(rsme)\n",
    "print \"Estimated out of sample Root mean squared error for this model is \", sum(outsample_rsme)/5\n",
    "print 'Estimated out of sample R-square for this model is',sum(outsample_r2)/5\n",
    "print 'Estimated in sample R-square for this model is',sum(insample_r2)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression with Lasso and log transformation\n",
    "insample_r2=[]\n",
    "outsample_r2=[]\n",
    "outsample_rsme=[]\n",
    "for i in range (5):\n",
    "    training, testing = train_test_split(train, test_size=0.2)\n",
    "    training = training.set_index([list(range(len(training)))])\n",
    "    for i in range(len(training[\"SalePrice\"])):\n",
    "        training.loc[i,('SalePrice')] = math.log(training.loc[i,('SalePrice')])    \n",
    "    X = training.drop(['SalePrice'],axis = 1)\n",
    "    Y = training['SalePrice']\n",
    "    testing = testing.set_index([list(range(len(testing)))])\n",
    "    for i in range(len(testing[\"SalePrice\"])):\n",
    "        testing.loc[i,('SalePrice')] = math.log(testing.loc[i,('SalePrice')])\n",
    "    test_x=testing.drop(['SalePrice'],axis = 1)\n",
    "    test_y=testing['SalePrice']\n",
    "    alpha=np.arange(0,30,0.1)\n",
    "    singlefeatures = list(X)\n",
    "    lasso = linear_model.LassoCV(alphas=alpha,cv =5).fit(X,Y)\n",
    "    lassofeatures = np.array(singlefeatures)[np.abs(lasso.coef_)>1e-8]\n",
    "    lm = smf.ols('SalePrice ~ '+' + '.join(lassofeatures), data=training).fit()\n",
    "    insample_r2.append(lm.rsquared)\n",
    "    rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((\n",
    "    test_y.mean()-test_y)**2)\n",
    "    outsample_r2.append(rsq)\n",
    "    for i in range(len(testing[\"SalePrice\"])):\n",
    "        testing.loc[i,('SalePrice')] = math.exp(testing.loc[i,('SalePrice')])\n",
    "    prediction = lm.predict(test_x)\n",
    "    for i in range(len(prediction)):\n",
    "        prediction[i]=math.exp(prediction[i])\n",
    "    rsme = sqrt(mean_squared_error(test_y, prediction))\n",
    "    outsample_rsme.append(rsme)\n",
    "print \"Estimated out of sample Root mean squared error for this model is \", sum(outsample_rsme)/5\n",
    "print 'Estimated out of sample R-square for this model is',sum(outsample_r2)/5\n",
    "print 'Estimated in sample R-square for this model is',sum(insample_r2)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pt a Best Classfication Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "lm = linearRegression(train.drop(['SalePrice'], axis=1),'SaleOver2k')\n",
    "CVforClassificationModels(train,'SaleOver2k',lm,'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "train, test = train_test_split(data, test_size=0.2,random_state=3)\n",
    "neigh = KNeighborsClassifier(n_neighbors=1) # 1 is the best one using CV\n",
    "neigh.fit(train.drop(['SalePrice','SaleOver2k'],axis=1), train['SaleOver2k']) \n",
    "a = sum(neigh.predict(test.drop(['SalePrice','SaleOver2k'],axis=1))*test['SaleOver2k'])/sum(train['SaleOver2k'])\n",
    "print 'Estimated out of sample accuracy for this model is ' + str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected variable model\n",
    "data2 = pd.read_excel(\"NewData.xlsx\")\n",
    "SaleOver2k = (np.array([data2['SalePrice']>200000])*1).reshape(len(data2),1)\n",
    "data2= data2.assign(SaleOver2k = SaleOver2k)\n",
    "singlefeatures = data2.columns[:-2]\n",
    "features = list(singlefeatures)\n",
    "for i in range(len(features)):\n",
    "    features[i] = \"\".join(features[i].split())\n",
    "    features[i] = features[i].replace('.','DOT')\n",
    "singlefeatures = features\n",
    "features.append('SalePrice')\n",
    "features.append('SaleOver2k')\n",
    "data2.columns = features\n",
    "train2, test2 = train_test_split(data2, test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected variable\n",
    "lm = linearRegression(train2.drop(['SalePrice'], axis=1),'SaleOver2k')\n",
    "CVforClassificationModels(train2,'SaleOver2k',lm,'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected variable with log transformation\n",
    "lm = linearRegression(train2.drop(['SalePrice'], axis=1),'SaleOver2k')\n",
    "CVforClassificationModels(train2,'SaleOver2k',lm,'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all variables with logistic model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train.drop(['SalePrice','SaleOver2k'],axis=1),train['SaleOver2k'])\n",
    "CVforClassificationModels(train.drop(['SalePrice'],axis=1),'SaleOver2k',lr,\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ExterQual'] = data['ExterQual'].replace('Ex', 5)\n",
    "data['ExterQual'] = data['ExterQual'].replace('Gd', 4)\n",
    "data['ExterQual'] = data['ExterQual'].replace('TA', 3)\n",
    "data['ExterQual'] = data['ExterQual'].replace('Fa', 2)\n",
    "data['ExterQual'] = data['ExterQual'].replace('Po', 1)\n",
    "data['ExterCond'] = data['ExterCond'].replace('Ex', 5)\n",
    "data['ExterCond'] = data['ExterCond'].replace('Gd', 4)\n",
    "data['ExterCond'] = data['ExterCond'].replace('TA', 3)\n",
    "data['ExterCond'] = data['ExterCond'].replace('Fa', 2)\n",
    "data['ExterCond'] = data['ExterCond'].replace('Po', 1)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('Ex', 5)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('Gd', 4)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('TA', 3)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('Fa', 2)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('Po', 1)\n",
    "data['BsmtQual'] = data['BsmtQual'].replace('No Basement', 0)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('Ex', 5)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('Gd', 4)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('TA', 3)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('Fa', 2)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('Po', 1)\n",
    "data['BsmtCond'] = data['BsmtCond'].replace('No Basement', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all variables with logistic model with selected variables\n",
    "lr = LogisticRegression()\n",
    "lr.fit(data.drop(['SalePrice','SaleOver2k'],axis=1),data['SaleOver2k'])\n",
    "CVforClassificationModels(data.drop(['SalePrice'],axis=1),'SaleOver2k',lr,\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Result for accurancy is  0.9314536961230777\n"
     ]
    }
   ],
   "source": [
    "#out of sample prediction\n",
    "lr = LogisticRegression()\n",
    "lr.fit(data.drop(['SalePrice','SaleOver2k'],axis=1),data['SaleOver2k'])\n",
    "FinalClassificationTest(data.drop(['SalePrice'],axis=1),'SaleOver2k',lr,\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Result for accurancy is  0.9156626506024097\n"
     ]
    }
   ],
   "source": [
    "#out of sample prediction\n",
    "lr = LogisticRegression()\n",
    "lr.fit(test.drop(['SalePrice','SaleOver2k'],axis=1),test['SaleOver2k'])\n",
    "FinalClassificationTest(data.drop(['SalePrice'],axis=1),'SaleOver2k',lr,\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index([list(range(len(train)))])\n",
    "for i in range(len(train[\"SalePrice\"])):\n",
    "    train.loc[i,('SalePrice')] = math.log(train.loc[i,('SalePrice')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['SalePrice'], axis=1)\n",
    "Y = train['SalePrice']\n",
    "alpha=np.arange(0,30,0.1)\n",
    "singlefeatures = list(X)\n",
    "lasso = linear_model.LassoCV(alphas=alpha,cv =5).fit(X,Y)\n",
    "lassofeatures = np.array(singlefeatures)[np.abs(lasso.coef_)>1e-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index([list(range(len(test)))])\n",
    "for i in range(len(test[\"SalePrice\"])):\n",
    "    test.loc[i,('SalePrice')] = math.log(test.loc[i,('SalePrice')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is in-sample R-square:0.9212655271253929\n",
      "Here is the out-of-sample R-square:0.87109017926\n"
     ]
    }
   ],
   "source": [
    "lm = smf.ols('SalePrice ~ '+' + '.join(lassofeatures), data=train).fit()\n",
    "print 'Here is in-sample R-square:'+str(lm.rsquared)\n",
    "test_x=test.drop(['SalePrice'], axis=1)\n",
    "test_y=test['SalePrice']\n",
    "rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((\n",
    "    test_y.mean()-test_y)**2)\n",
    "print 'Here is the out-of-sample R-square:'+str(rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test[\"SalePrice\"])):\n",
    "    test.loc[i,('SalePrice')] = math.exp(test.loc[i,('SalePrice')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lm.predict(test_x)\n",
    "for i in range(len(prediction)):\n",
    "      prediction[i]=math.exp(prediction[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error of the prediction is  44478.1758102\n"
     ]
    }
   ],
   "source": [
    "rms_test = sqrt(mean_squared_error(test['SalePrice'], prediction))\n",
    "print \"Root mean squared error of the prediction is \", rms_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASELINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlefeatures=train.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train[\"SalePrice\"])):\n",
    "    train.loc[i,('SalePrice')] = math.exp(train.loc[i,('SalePrice')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is in-sample R-square:0.8972564589848324\n",
      "Here is the out-of-sample R-square:0.846172299948\n"
     ]
    }
   ],
   "source": [
    "lm = smf.ols('SalePrice ~ '+' + '.join(singlefeatures), data=train).fit()\n",
    "print 'Here is in-sample R-square:'+str(lm.rsquared)\n",
    "rsq = 1. - np.sum((lm.predict(test_x)-test_y)**2)/np.sum((\n",
    "    test_y.mean()-test_y)**2)\n",
    "print 'Here is the out-of-sample R-square:'+str(rsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error of the prediction is  32407.6200487\n"
     ]
    }
   ],
   "source": [
    "rms_test = sqrt(mean_squared_error(test['SalePrice'], lm.predict(test_x)))\n",
    "print \"Root mean squared error of the prediction is \", rms_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
